{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\matis\\anaconda3202007\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import tflearn.datasets.oxflower17 as oxflower17\n",
    "X, Y = oxflower17.load_data(one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(17, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 26, 26, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 22, 22, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 1, 384)         1536      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              1576960   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 17)                69649     \n",
      "=================================================================\n",
      "Total params: 21,883,153\n",
      "Trainable params: 21,881,681\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1224 samples, validate on 136 samples\n",
      "Epoch 1/100\n",
      "1224/1224 [==============================] - ETA: 0s - loss: 4.3369 - acc: 0.2353WARNING:tensorflow:From C:\\Users\\matis\\anaconda3202007\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "1224/1224 [==============================] - 49s 40ms/sample - loss: 4.3369 - acc: 0.2353 - val_loss: 10.5978 - val_acc: 0.0515\n",
      "Epoch 2/100\n",
      "1224/1224 [==============================] - 47s 38ms/sample - loss: 3.3267 - acc: 0.3194 - val_loss: 5.0373 - val_acc: 0.0735\n",
      "Epoch 3/100\n",
      "1224/1224 [==============================] - 48s 39ms/sample - loss: 2.7218 - acc: 0.3578 - val_loss: 4.8310 - val_acc: 0.0735\n",
      "Epoch 4/100\n",
      "1224/1224 [==============================] - 52s 42ms/sample - loss: 2.3189 - acc: 0.4150 - val_loss: 5.4878 - val_acc: 0.1176\n",
      "Epoch 5/100\n",
      "1224/1224 [==============================] - 52s 43ms/sample - loss: 2.4984 - acc: 0.4085 - val_loss: 7.2404 - val_acc: 0.1250\n",
      "Epoch 6/100\n",
      "1224/1224 [==============================] - 52s 43ms/sample - loss: 2.2386 - acc: 0.4322 - val_loss: 3.1416 - val_acc: 0.1912\n",
      "Epoch 7/100\n",
      "1224/1224 [==============================] - 61s 50ms/sample - loss: 2.2174 - acc: 0.4534 - val_loss: 2.9870 - val_acc: 0.2647\n",
      "Epoch 8/100\n",
      "1224/1224 [==============================] - 56s 46ms/sample - loss: 1.8472 - acc: 0.4910 - val_loss: 4.3266 - val_acc: 0.1618\n",
      "Epoch 9/100\n",
      "1224/1224 [==============================] - 52s 43ms/sample - loss: 2.0264 - acc: 0.4730 - val_loss: 4.0093 - val_acc: 0.2941\n",
      "Epoch 10/100\n",
      "1224/1224 [==============================] - 53s 43ms/sample - loss: 1.8240 - acc: 0.5204 - val_loss: 2.1664 - val_acc: 0.4118\n",
      "Epoch 11/100\n",
      "1224/1224 [==============================] - 52s 43ms/sample - loss: 1.8607 - acc: 0.5082 - val_loss: 2.3936 - val_acc: 0.4412\n",
      "Epoch 12/100\n",
      "1224/1224 [==============================] - 49s 40ms/sample - loss: 1.4105 - acc: 0.5605 - val_loss: 4.0585 - val_acc: 0.2868\n",
      "Epoch 13/100\n",
      "1224/1224 [==============================] - 48s 39ms/sample - loss: 1.5981 - acc: 0.5735 - val_loss: 2.7969 - val_acc: 0.3676\n",
      "Epoch 14/100\n",
      "1224/1224 [==============================] - 53s 44ms/sample - loss: 2.0678 - acc: 0.5008 - val_loss: 6.2455 - val_acc: 0.1838\n",
      "Epoch 15/100\n",
      "1224/1224 [==============================] - 51s 42ms/sample - loss: 1.8742 - acc: 0.5049 - val_loss: 2.9120 - val_acc: 0.3676\n",
      "Epoch 16/100\n",
      "1224/1224 [==============================] - 53s 43ms/sample - loss: 1.7143 - acc: 0.5327 - val_loss: 2.4985 - val_acc: 0.3750\n",
      "Epoch 17/100\n",
      "1224/1224 [==============================] - 51s 42ms/sample - loss: 1.4911 - acc: 0.5735 - val_loss: 2.3673 - val_acc: 0.4485\n",
      "Epoch 18/100\n",
      "1224/1224 [==============================] - 55s 45ms/sample - loss: 1.3193 - acc: 0.6193 - val_loss: 2.5703 - val_acc: 0.3529\n",
      "Epoch 19/100\n",
      "1224/1224 [==============================] - 52s 42ms/sample - loss: 1.3619 - acc: 0.6217 - val_loss: 3.1185 - val_acc: 0.3824\n",
      "Epoch 20/100\n",
      "1224/1224 [==============================] - 53s 44ms/sample - loss: 1.2900 - acc: 0.6438 - val_loss: 3.0643 - val_acc: 0.3897\n",
      "Epoch 21/100\n",
      "1224/1224 [==============================] - 51s 41ms/sample - loss: 1.3259 - acc: 0.6242 - val_loss: 2.0648 - val_acc: 0.5294\n",
      "Epoch 22/100\n",
      "1224/1224 [==============================] - 55s 45ms/sample - loss: 1.0436 - acc: 0.6765 - val_loss: 3.2740 - val_acc: 0.3235\n",
      "Epoch 23/100\n",
      "1224/1224 [==============================] - 67s 55ms/sample - loss: 1.3963 - acc: 0.6275 - val_loss: 2.4794 - val_acc: 0.3971\n",
      "Epoch 24/100\n",
      "1224/1224 [==============================] - 67s 55ms/sample - loss: 1.3616 - acc: 0.6544 - val_loss: 2.3390 - val_acc: 0.5147\n",
      "Epoch 25/100\n",
      "1224/1224 [==============================] - 67s 54ms/sample - loss: 1.2647 - acc: 0.6634 - val_loss: 2.1605 - val_acc: 0.5294\n",
      "Epoch 26/100\n",
      "1224/1224 [==============================] - 66s 54ms/sample - loss: 1.3185 - acc: 0.6732 - val_loss: 2.8219 - val_acc: 0.4632\n",
      "Epoch 27/100\n",
      "1224/1224 [==============================] - 66s 54ms/sample - loss: 1.2092 - acc: 0.6928 - val_loss: 1.9942 - val_acc: 0.5588\n",
      "Epoch 28/100\n",
      "1224/1224 [==============================] - 69s 56ms/sample - loss: 1.2119 - acc: 0.6944 - val_loss: 2.3060 - val_acc: 0.5294\n",
      "Epoch 29/100\n",
      "1224/1224 [==============================] - 72s 59ms/sample - loss: 1.2573 - acc: 0.6593 - val_loss: 2.9647 - val_acc: 0.4265\n",
      "Epoch 30/100\n",
      "1224/1224 [==============================] - 72s 59ms/sample - loss: 1.0950 - acc: 0.7100 - val_loss: 2.7750 - val_acc: 0.5074\n",
      "Epoch 31/100\n",
      "1224/1224 [==============================] - 73s 59ms/sample - loss: 0.8388 - acc: 0.7590 - val_loss: 3.4910 - val_acc: 0.4412\n",
      "Epoch 32/100\n",
      "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.7132 - acc: 0.7958 - val_loss: 2.0516 - val_acc: 0.5515\n",
      "Epoch 33/100\n",
      "1224/1224 [==============================] - 73s 59ms/sample - loss: 1.0303 - acc: 0.7279 - val_loss: 2.6851 - val_acc: 0.4118\n",
      "Epoch 34/100\n",
      "1224/1224 [==============================] - 73s 59ms/sample - loss: 0.9372 - acc: 0.7492 - val_loss: 3.1430 - val_acc: 0.3971\n",
      "Epoch 35/100\n",
      "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.8115 - acc: 0.7729 - val_loss: 3.0865 - val_acc: 0.4265\n",
      "Epoch 36/100\n",
      "1224/1224 [==============================] - 58s 48ms/sample - loss: 0.7990 - acc: 0.7827 - val_loss: 2.7213 - val_acc: 0.4485\n",
      "Epoch 37/100\n",
      "1224/1224 [==============================] - 47s 38ms/sample - loss: 0.7044 - acc: 0.8047 - val_loss: 1.8371 - val_acc: 0.6471\n",
      "Epoch 38/100\n",
      "1224/1224 [==============================] - 46s 38ms/sample - loss: 0.4494 - acc: 0.8627 - val_loss: 2.5877 - val_acc: 0.5294\n",
      "Epoch 39/100\n",
      "1224/1224 [==============================] - 46s 38ms/sample - loss: 0.7479 - acc: 0.8007 - val_loss: 2.8870 - val_acc: 0.5294\n",
      "Epoch 40/100\n",
      "1224/1224 [==============================] - 46s 38ms/sample - loss: 0.4619 - acc: 0.8627 - val_loss: 2.8259 - val_acc: 0.5221\n",
      "Epoch 41/100\n",
      "1224/1224 [==============================] - 47s 38ms/sample - loss: 0.5031 - acc: 0.8497 - val_loss: 2.4029 - val_acc: 0.5809\n",
      "Epoch 42/100\n",
      "1224/1224 [==============================] - 46s 38ms/sample - loss: 0.6257 - acc: 0.8399 - val_loss: 3.4205 - val_acc: 0.5074\n",
      "Epoch 43/100\n",
      "1224/1224 [==============================] - 47s 38ms/sample - loss: 0.5746 - acc: 0.8505 - val_loss: 2.5087 - val_acc: 0.5882\n",
      "Epoch 44/100\n",
      "1224/1224 [==============================] - 46s 38ms/sample - loss: 0.3555 - acc: 0.8815 - val_loss: 1.8343 - val_acc: 0.6103\n",
      "Epoch 45/100\n",
      "1224/1224 [==============================] - 46s 38ms/sample - loss: 0.4931 - acc: 0.8693 - val_loss: 2.7486 - val_acc: 0.5221\n",
      "Epoch 46/100\n",
      "1224/1224 [==============================] - 47s 38ms/sample - loss: 0.4720 - acc: 0.8578 - val_loss: 2.7059 - val_acc: 0.4926\n",
      "Epoch 47/100\n",
      "1224/1224 [==============================] - 46s 38ms/sample - loss: 0.3967 - acc: 0.8897 - val_loss: 2.7111 - val_acc: 0.5515\n",
      "Epoch 48/100\n",
      "1224/1224 [==============================] - 46s 38ms/sample - loss: 0.3705 - acc: 0.8889 - val_loss: 2.8433 - val_acc: 0.5221\n",
      "Epoch 49/100\n",
      "1224/1224 [==============================] - 46s 38ms/sample - loss: 0.3695 - acc: 0.9011 - val_loss: 3.8233 - val_acc: 0.5221\n",
      "Epoch 50/100\n",
      "1224/1224 [==============================] - 46s 38ms/sample - loss: 0.6697 - acc: 0.8350 - val_loss: 3.1070 - val_acc: 0.4118\n",
      "Epoch 51/100\n",
      "1224/1224 [==============================] - 46s 38ms/sample - loss: 0.3952 - acc: 0.8791 - val_loss: 3.3831 - val_acc: 0.4706\n",
      "Epoch 52/100\n",
      "1224/1224 [==============================] - 4743s 4s/sample - loss: 0.6105 - acc: 0.8399 - val_loss: 2.8131 - val_acc: 0.5294\n",
      "Epoch 53/100\n",
      "1224/1224 [==============================] - 53s 43ms/sample - loss: 0.5551 - acc: 0.8619 - val_loss: 3.6242 - val_acc: 0.4559\n",
      "Epoch 54/100\n",
      "1224/1224 [==============================] - 56s 46ms/sample - loss: 0.5119 - acc: 0.8652 - val_loss: 2.9584 - val_acc: 0.5221\n",
      "Epoch 55/100\n",
      "1224/1224 [==============================] - 53s 43ms/sample - loss: 0.5840 - acc: 0.8652 - val_loss: 2.8325 - val_acc: 0.5441\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1224/1224 [==============================] - 51s 42ms/sample - loss: 0.5813 - acc: 0.8407 - val_loss: 2.9958 - val_acc: 0.5956\n",
      "Epoch 57/100\n",
      "1224/1224 [==============================] - 51s 42ms/sample - loss: 0.4122 - acc: 0.8979 - val_loss: 2.5132 - val_acc: 0.6397\n",
      "Epoch 58/100\n",
      "1224/1224 [==============================] - 52s 42ms/sample - loss: 0.5850 - acc: 0.8709 - val_loss: 1.9047 - val_acc: 0.6765\n",
      "Epoch 59/100\n",
      "1224/1224 [==============================] - 52s 42ms/sample - loss: 0.3127 - acc: 0.9150 - val_loss: 3.2248 - val_acc: 0.5662\n",
      "Epoch 60/100\n",
      "1224/1224 [==============================] - 47s 38ms/sample - loss: 0.3957 - acc: 0.9248 - val_loss: 2.7963 - val_acc: 0.5809\n",
      "Epoch 61/100\n",
      "1224/1224 [==============================] - 48s 39ms/sample - loss: 0.2065 - acc: 0.9404 - val_loss: 2.0163 - val_acc: 0.6765\n",
      "Epoch 62/100\n",
      "1224/1224 [==============================] - 48s 39ms/sample - loss: 0.2017 - acc: 0.9404 - val_loss: 2.5832 - val_acc: 0.6250\n",
      "Epoch 63/100\n",
      "1224/1224 [==============================] - 57s 46ms/sample - loss: 0.1290 - acc: 0.9616 - val_loss: 2.5978 - val_acc: 0.5809\n",
      "Epoch 64/100\n",
      "1224/1224 [==============================] - 52s 42ms/sample - loss: 0.1472 - acc: 0.9567 - val_loss: 2.5450 - val_acc: 0.6618\n",
      "Epoch 65/100\n",
      "1224/1224 [==============================] - 50s 41ms/sample - loss: 0.1264 - acc: 0.9592 - val_loss: 2.7369 - val_acc: 0.6103\n",
      "Epoch 66/100\n",
      "1224/1224 [==============================] - 51s 42ms/sample - loss: 0.3227 - acc: 0.9248 - val_loss: 2.5018 - val_acc: 0.6397\n",
      "Epoch 67/100\n",
      "1224/1224 [==============================] - 49s 40ms/sample - loss: 0.3672 - acc: 0.9158 - val_loss: 3.7563 - val_acc: 0.5147\n",
      "Epoch 68/100\n",
      "1224/1224 [==============================] - 49s 40ms/sample - loss: 0.2453 - acc: 0.9346 - val_loss: 3.0155 - val_acc: 0.5662\n",
      "Epoch 69/100\n",
      "1224/1224 [==============================] - 49s 40ms/sample - loss: 0.3233 - acc: 0.9208 - val_loss: 2.3928 - val_acc: 0.6471\n",
      "Epoch 70/100\n",
      "1224/1224 [==============================] - 48s 39ms/sample - loss: 0.3889 - acc: 0.9085 - val_loss: 2.6078 - val_acc: 0.6250\n",
      "Epoch 71/100\n",
      "1224/1224 [==============================] - 49s 40ms/sample - loss: 0.3101 - acc: 0.9069 - val_loss: 3.8503 - val_acc: 0.5294\n",
      "Epoch 72/100\n",
      "1224/1224 [==============================] - 48s 39ms/sample - loss: 0.3629 - acc: 0.9085 - val_loss: 5.0065 - val_acc: 0.4044\n",
      "Epoch 73/100\n",
      "1224/1224 [==============================] - 53s 44ms/sample - loss: 0.3874 - acc: 0.8995 - val_loss: 4.2576 - val_acc: 0.5000\n",
      "Epoch 74/100\n",
      "1224/1224 [==============================] - 60s 49ms/sample - loss: 0.3297 - acc: 0.9191 - val_loss: 3.5966 - val_acc: 0.5809\n",
      "Epoch 75/100\n",
      "1224/1224 [==============================] - 53s 43ms/sample - loss: 0.1828 - acc: 0.9485 - val_loss: 4.0304 - val_acc: 0.5221\n",
      "Epoch 76/100\n",
      "1224/1224 [==============================] - 56s 46ms/sample - loss: 0.1745 - acc: 0.9453 - val_loss: 2.9045 - val_acc: 0.5956\n",
      "Epoch 77/100\n",
      "1224/1224 [==============================] - 52s 43ms/sample - loss: 0.2992 - acc: 0.9175 - val_loss: 3.1390 - val_acc: 0.5662\n",
      "Epoch 78/100\n",
      "1224/1224 [==============================] - 52s 43ms/sample - loss: 0.2616 - acc: 0.9232 - val_loss: 3.0807 - val_acc: 0.6176\n",
      "Epoch 79/100\n",
      "1224/1224 [==============================] - 52s 43ms/sample - loss: 0.3635 - acc: 0.9240 - val_loss: 4.4713 - val_acc: 0.4779\n",
      "Epoch 80/100\n",
      "1224/1224 [==============================] - 54s 44ms/sample - loss: 0.5691 - acc: 0.8807 - val_loss: 4.2161 - val_acc: 0.5221\n",
      "Epoch 81/100\n",
      "1224/1224 [==============================] - 52s 43ms/sample - loss: 0.7832 - acc: 0.8497 - val_loss: 4.0658 - val_acc: 0.5662\n",
      "Epoch 82/100\n",
      "1224/1224 [==============================] - 54s 44ms/sample - loss: 0.5283 - acc: 0.8758 - val_loss: 3.6683 - val_acc: 0.5662\n",
      "Epoch 83/100\n",
      "1224/1224 [==============================] - 56s 46ms/sample - loss: 0.3020 - acc: 0.9109 - val_loss: 3.0665 - val_acc: 0.6029\n",
      "Epoch 84/100\n",
      "1224/1224 [==============================] - 54s 44ms/sample - loss: 0.2154 - acc: 0.9355 - val_loss: 2.8191 - val_acc: 0.6765\n",
      "Epoch 85/100\n",
      "1224/1224 [==============================] - 53s 43ms/sample - loss: 0.1515 - acc: 0.9600 - val_loss: 3.1044 - val_acc: 0.6765\n",
      "Epoch 86/100\n",
      "1224/1224 [==============================] - 57s 46ms/sample - loss: 0.2082 - acc: 0.9461 - val_loss: 3.3468 - val_acc: 0.5882\n",
      "Epoch 87/100\n",
      "1224/1224 [==============================] - 55s 45ms/sample - loss: 0.1859 - acc: 0.9551 - val_loss: 3.6592 - val_acc: 0.6029\n",
      "Epoch 88/100\n",
      "1224/1224 [==============================] - 51s 42ms/sample - loss: 0.3702 - acc: 0.9175 - val_loss: 4.1794 - val_acc: 0.5368\n",
      "Epoch 89/100\n",
      "1224/1224 [==============================] - 50s 41ms/sample - loss: 0.1071 - acc: 0.9657 - val_loss: 2.7020 - val_acc: 0.6985\n",
      "Epoch 90/100\n",
      "1224/1224 [==============================] - 53s 43ms/sample - loss: 0.0562 - acc: 0.9828 - val_loss: 2.5868 - val_acc: 0.6838\n",
      "Epoch 91/100\n",
      "1224/1224 [==============================] - 56s 45ms/sample - loss: 0.1524 - acc: 0.9592 - val_loss: 3.7485 - val_acc: 0.5515\n",
      "Epoch 92/100\n",
      "1224/1224 [==============================] - 48s 40ms/sample - loss: 0.3268 - acc: 0.9420 - val_loss: 2.9294 - val_acc: 0.6103\n",
      "Epoch 93/100\n",
      "1224/1224 [==============================] - 57s 46ms/sample - loss: 0.1016 - acc: 0.9714 - val_loss: 2.9570 - val_acc: 0.6691\n",
      "Epoch 94/100\n",
      "1224/1224 [==============================] - 57s 47ms/sample - loss: 0.1633 - acc: 0.9641 - val_loss: 3.9305 - val_acc: 0.5515\n",
      "Epoch 95/100\n",
      "1224/1224 [==============================] - 52s 42ms/sample - loss: 0.3769 - acc: 0.9240 - val_loss: 3.1100 - val_acc: 0.6324\n",
      "Epoch 96/100\n",
      "1224/1224 [==============================] - 49s 40ms/sample - loss: 0.3348 - acc: 0.9330 - val_loss: 3.3611 - val_acc: 0.6103\n",
      "Epoch 97/100\n",
      "1224/1224 [==============================] - 47s 39ms/sample - loss: 0.4350 - acc: 0.9142 - val_loss: 3.6090 - val_acc: 0.5515\n",
      "Epoch 98/100\n",
      "1224/1224 [==============================] - 48s 39ms/sample - loss: 0.2423 - acc: 0.9404 - val_loss: 3.7691 - val_acc: 0.5441\n",
      "Epoch 99/100\n",
      "1224/1224 [==============================] - 55s 45ms/sample - loss: 0.1483 - acc: 0.9559 - val_loss: 3.7667 - val_acc: 0.5882\n",
      "Epoch 100/100\n",
      "1224/1224 [==============================] - 48s 40ms/sample - loss: 0.8706 - acc: 0.8595 - val_loss: 7.1451 - val_acc: 0.3162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22be5f9ca00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=64, epochs=100, verbose=1, validation_split=0.1, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
