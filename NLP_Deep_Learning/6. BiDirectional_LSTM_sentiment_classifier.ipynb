{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM\n",
    "from keras.layers.wrappers import Bidirectional # new! \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/biLSTM'\n",
    "\n",
    "# training:\n",
    "epochs = 6\n",
    "batch_size = 128\n",
    "\n",
    "# vector-space embedding: \n",
    "n_dim = 64 \n",
    "n_unique_words = 10000 \n",
    "max_review_length = 200 # doubled!\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2 \n",
    "\n",
    "# LSTM layer architecture:\n",
    "n_lstm = 256 \n",
    "drop_lstm = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words) # removed n_words_to_skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length)) \n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(Bidirectional(LSTM(n_lstm, dropout=drop_lstm)))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 64)           640000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 200, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 512)               657408    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,297,921\n",
      "Trainable params: 1,297,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM layer parameters double due to both reading directions\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "196/196 [==============================] - 780s 4s/step - loss: 0.5793 - accuracy: 0.6892 - val_loss: 0.3672 - val_accuracy: 0.8488\n",
      "Epoch 2/6\n",
      "196/196 [==============================] - 797s 4s/step - loss: 0.3046 - accuracy: 0.8758 - val_loss: 0.3056 - val_accuracy: 0.8741\n",
      "Epoch 3/6\n",
      "196/196 [==============================] - 812s 4s/step - loss: 0.2350 - accuracy: 0.9111 - val_loss: 0.3755 - val_accuracy: 0.8666\n",
      "Epoch 4/6\n",
      "196/196 [==============================] - 777s 4s/step - loss: 0.1910 - accuracy: 0.9280 - val_loss: 0.3203 - val_accuracy: 0.8675\n",
      "Epoch 5/6\n",
      "196/196 [==============================] - 736s 4s/step - loss: 0.1603 - accuracy: 0.9415 - val_loss: 0.3598 - val_accuracy: 0.8472\n",
      "Epoch 6/6\n",
      "196/196 [==============================] - 1083s 6s/step - loss: 0.1373 - accuracy: 0.9502 - val_loss: 0.3855 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a61761cd00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - with this toy dataset, the complex interplay of words over long sentence segments, won't be learned much\n",
    "# - so our CNN picking up location-invariant segments of two to four words that predict review sentiment\n",
    "# - these are simpler and so easier to learn from the data\n",
    "# - CNN therefore outperforms on the IMDB data set\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.04.hdf5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-06b9224910f9>:1: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict_proba(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'94.12'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(roc_auc_score(y_valid, y_hat)*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
